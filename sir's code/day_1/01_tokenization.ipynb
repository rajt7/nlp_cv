{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"They told that their ages are 25 26 and 31 respectively.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of ages is: 82\n",
      "The average of ages is 27.33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[25, 26, 31]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the averages of ages mentioned in the statement\n",
    "age, count = 0, 0\n",
    "for s in sent.split(' '):\n",
    "    if s.isdigit():\n",
    "        age += int(s)\n",
    "        count += 1\n",
    "\n",
    "print(f\"The sum of ages is: {age}\")\n",
    "print(f\"The average of ages is {round(age/count, 2)}\")\n",
    "\n",
    "\n",
    "### Alternate Code\n",
    "words = sent.split()\n",
    "ages = [int(word) for word in words if word.isdigit()]\n",
    "ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = '''Hello friends!\n",
    "How are you? Welcome to Python Programming.'''\n",
    "\n",
    "# Find how many sentences are in it?\n",
    "punctuations = ['!', '?', '.']\n",
    "count = 0\n",
    "for char in sents:\n",
    "    if char in punctuations:\n",
    "        count += 1\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello friends! how are you? welcome to Python Programming.\n"
     ]
    }
   ],
   "source": [
    "sents = '''hello friends!\n",
    "how are you? welcome to Python Programming.'''\n",
    "\n",
    "words = sents.split()\n",
    "\n",
    "for i in range(len(words)):\n",
    "    letters = words[i].split()\n",
    "    for letter in letters:\n",
    "        if letter in punctuations:\n",
    "            words[i+1] = words[i+1].capitalize()\n",
    "\n",
    "\n",
    "new_str = ' '.join(words)\n",
    "print(new_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('indian')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello friends!', 'How are you?', 'Welcome to Python Programming.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sents = '''Hello friends! How are you? Welcome to Python Programming.'''\n",
    "\n",
    "sent_list = sent_tokenize(sents)\n",
    "sent_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends',\n",
       " '!',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sents = '''Hello friends! ,,, How are you? Welcome to Python Programming.'''\n",
    "\n",
    "words = word_tokenize(sents)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### List of all punctuations in python\n",
    "import string\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'friends', '!', 'How', 'are', 'you', '?', 'Welcome', 'to', 'Python', 'Programming', '.']\n",
      "25.0\n"
     ]
    }
   ],
   "source": [
    "### Percentage of punctuation symbols\n",
    "sents = '''Hello friends!\n",
    "How are you? Welcome to Python Programming.'''\n",
    "\n",
    "words = word_tokenize(sents)\n",
    "print(words)\n",
    "\n",
    "count = 0\n",
    "for word in words:\n",
    "    if word in string.punctuation:\n",
    "        count += 1\n",
    "\n",
    "print((count/len(words))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character to ASCII Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASCII Code to Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128514"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('üòÇ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üòÇ'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(128514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üòÑ'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(128516)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0x055)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§†'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0x0920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡•©'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0x0969)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡™∞‡™Ü'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0x0AB0) + chr(0x0A86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡™∞‡™æ‡™ú\n",
      "‡™∞‡´ã‡™π‡™ø‡™§\n",
      "‡™∞‡´Å‡™ö‡™ø‡™∞\n"
     ]
    }
   ],
   "source": [
    "names = ['‡™∞‡™æ‡™ú', '‡™∞‡´ã‡™π‡™ø‡™§', '‡™µ‡´á‡™¶‡™Æ‡™æ‡™®‡´Ä', '‡™∞‡´Å‡™ö‡™ø‡™∞']\n",
    "\n",
    "for name in names:\n",
    "    if name.startswith('‡™∞'):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§ï‡•Ö'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\u0915\\u0945'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‡™à‡™ï‡´ã‡™®‡´ã‡™Æ‡™ø‡™ï',\n",
       " '‡™ü‡™æ‡™à‡™Æ‡´ç‡™∏',\n",
       " '‡™¶‡´ç‡™µ‡™æ‡™∞‡™æ',\n",
       " '‡™π‡™æ‡™•',\n",
       " '‡™ß‡™∞‡™µ‡™æ‡™Æ‡™æ‡™Ç',\n",
       " '‡™Ü‡™µ‡´á‡™≤‡™æ',\n",
       " '‡™Ö‡™≠‡´ç‡™Ø‡™æ‡™∏',\n",
       " '‡™Æ‡´Å‡™ú‡™¨',\n",
       " '2019',\n",
       " '‡™•‡´Ä',\n",
       " '2035',\n",
       " '‡™¶‡™∞‡™Æ‡™ø‡™Ø‡™æ‡™®',\n",
       " '‡™∏‡´Å‡™∞‡™§',\n",
       " '‡™µ‡™ø‡™∂‡´ç‡™µ‡™®‡´Å‡™Ç',\n",
       " '‡™∏‡´å‡™•‡´Ä',\n",
       " '‡™ù‡™°‡™™‡™•‡´Ä',\n",
       " '‡™µ‡™ø‡™ï‡™∏‡™§‡´Å‡™Ç',\n",
       " '‡™∂‡™π‡´á‡™∞',\n",
       " '‡™¨‡™®‡™∂‡´á',\n",
       " '.']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '‡™à‡™ï‡´ã‡™®‡´ã‡™Æ‡™ø‡™ï ‡™ü‡™æ‡™à‡™Æ‡´ç‡™∏ ‡™¶‡´ç‡™µ‡™æ‡™∞‡™æ ‡™π‡™æ‡™• ‡™ß‡™∞‡™µ‡™æ‡™Æ‡™æ‡™Ç ‡™Ü‡™µ‡´á‡™≤‡™æ ‡™Ö‡™≠‡´ç‡™Ø‡™æ‡™∏ ‡™Æ‡´Å‡™ú‡™¨ 2019 ‡™•‡´Ä 2035 ‡™¶‡™∞‡™Æ‡™ø‡™Ø‡™æ‡™® ‡™∏‡´Å‡™∞‡™§ ‡™µ‡™ø‡™∂‡´ç‡™µ‡™®‡´Å‡™Ç ‡™∏‡´å‡™•‡´Ä ‡™ù‡™°‡™™‡™•‡´Ä ‡™µ‡™ø‡™ï‡™∏‡™§‡´Å‡™Ç ‡™∂‡™π‡´á‡™∞ ‡™¨‡™®‡™∂‡´á.'\n",
    "\n",
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White Space Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends!',\n",
       " ',',\n",
       " ',',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'Python',\n",
       " 'Programming.']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "sents = '''Hello friends! , ,\n",
    "How are you? Welcome to Python Programming.'''\n",
    "\n",
    "tk = WhitespaceTokenizer()\n",
    "\n",
    "tk.tokenize(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends!',\n",
       " ',\\nHow',\n",
       " 'are',\n",
       " 'you?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'Python',\n",
       " 'Programming.']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Space Tokenizer\n",
    "from nltk.tokenize import SpaceTokenizer\n",
    "\n",
    "sents = '''Hello friends! ,\n",
    "How are you? Welcome to Python Programming.'''\n",
    "\n",
    "tk = SpaceTokenizer()\n",
    "\n",
    "tk.tokenize(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello friends!', 'How are you? Welcome to Python Programming.']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Line Tokenizer\n",
    "from nltk.tokenize import LineTokenizer\n",
    "\n",
    "sents = '''Hello friends!\n",
    "How are you? Welcome to Python Programming.'''\n",
    "\n",
    "tk = LineTokenizer()\n",
    "\n",
    "tk.tokenize(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello friends!\\nHow are you?', 'Welcome', 'to Python Programming.']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Tab Tokenizer\n",
    "from nltk.tokenize import TabTokenizer\n",
    "\n",
    "sents = '''Hello friends!\n",
    "How are you?\\tWelcome\\tto Python Programming.'''\n",
    "\n",
    "tk = TabTokenizer()\n",
    "\n",
    "tk.tokenize(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello friends! :) :! üòÇ\n",
      "How are you? Welcome to #Python Programmingüòé\n",
      "Check my web: https://python.org\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends',\n",
       " '!',\n",
       " ':)',\n",
       " ':',\n",
       " '!',\n",
       " 'üòÇ',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " '#Python',\n",
       " 'Programming',\n",
       " 'üòé',\n",
       " 'Check',\n",
       " 'my',\n",
       " 'web',\n",
       " ':',\n",
       " 'https://python.org']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Tweet Toknizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "sents = '''Hello friends! :) :! üòÇ\n",
    "How are you? Welcome to #Python Programmingüòé\n",
    "Check my web: https://python.org'''\n",
    "print(sents)\n",
    "\n",
    "tk = TweetTokenizer()\n",
    "tk.tokenize(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends',\n",
       " '!',\n",
       " ':',\n",
       " ')',\n",
       " ':',\n",
       " '!',\n",
       " 'üòÇ',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " '#',\n",
       " 'Python',\n",
       " 'Programmingüòé',\n",
       " 'Check',\n",
       " 'my',\n",
       " 'web',\n",
       " ':',\n",
       " 'https',\n",
       " ':',\n",
       " '//python.org']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wk = word_tokenize(sents)\n",
    "wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['van rossom',\n",
       " 'is',\n",
       " 'in',\n",
       " 'pune',\n",
       " 'today',\n",
       " '.',\n",
       " 'we',\n",
       " 'welcomed',\n",
       " 'van rossom',\n",
       " 'here',\n",
       " '.']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Multi-Word Expression Tokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "sent = \"Van Rossom is in Pune today. We welcomed van rossom here.\"\n",
    "\n",
    "tk = MWETokenizer(sent, separator=' ')\n",
    "tk.add_mwe(['van', 'rossom'])\n",
    "tk.tokenize(word_tokenize(sent.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends',\n",
       " 'How-are',\n",
       " 'you',\n",
       " 'Wel',\n",
       " 'come',\n",
       " 'to',\n",
       " 'Python',\n",
       " 'Progra',\n",
       " 'mming',\n",
       " '']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Custom Tokenizer\n",
    "import re\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    return re.split(r\"[,.;?!\\s]+\", text)\n",
    "\n",
    "\n",
    "sents = '''Hello friends!\n",
    "How-are you? Wel.come to\\tPython Progra?mming.'''\n",
    "\n",
    "custom_tokenizer(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roll\\tname\\tclass\\tmarks\\tage\\n1\\tanil\\tTE\\t56.77\\t22\\n2\\tamit\\tTE\\t59.77\\t21\\n3\\taniket\\tBE\\t76.88\\t19\\n4\\tajinkya\\tTE\\t69.66\\t20\\n5\\tasha\\tTE\\t63.28\\t20\\n6\\tayesha\\tBE\\t49.55\\t20\\n7\\tamar\\tBE\\t65.34\\t19\\n8\\tamita\\tBE\\t68.33\\t23\\n9\\tamol\\tTE\\t56.75\\t20\\n10\\tanmol\\tBE\\t78.66\\t21\\n'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/student3.tsv') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    return re.split(r\"[\\n\\t]+\", text)\n",
    "\n",
    "data = custom_tokenizer(data[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['roll', 'name', 'class', 'marks', 'age'],\n",
       "       ['1', 'anil', 'TE', '56.77', '22'],\n",
       "       ['2', 'amit', 'TE', '59.77', '21'],\n",
       "       ['3', 'aniket', 'BE', '76.88', '19'],\n",
       "       ['4', 'ajinkya', 'TE', '69.66', '20'],\n",
       "       ['5', 'asha', 'TE', '63.28', '20'],\n",
       "       ['6', 'ayesha', 'BE', '49.55', '20'],\n",
       "       ['7', 'amar', 'BE', '65.34', '19'],\n",
       "       ['8', 'amita', 'BE', '68.33', '23'],\n",
       "       ['9', 'amol', 'TE', '56.75', '20'],\n",
       "       ['10', 'anmol', 'BE', '78.66', '21']], dtype='<U7')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.array(data).reshape(-1, 5)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['roll', 'name', 'class', 'marks', 'age'], dtype='<U7')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roll</th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "      <th>marks</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>anil</td>\n",
       "      <td>TE</td>\n",
       "      <td>56.77</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>amit</td>\n",
       "      <td>TE</td>\n",
       "      <td>59.77</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aniket</td>\n",
       "      <td>BE</td>\n",
       "      <td>76.88</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ajinkya</td>\n",
       "      <td>TE</td>\n",
       "      <td>69.66</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>asha</td>\n",
       "      <td>TE</td>\n",
       "      <td>63.28</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>ayesha</td>\n",
       "      <td>BE</td>\n",
       "      <td>49.55</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>amar</td>\n",
       "      <td>BE</td>\n",
       "      <td>65.34</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>amita</td>\n",
       "      <td>BE</td>\n",
       "      <td>68.33</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>amol</td>\n",
       "      <td>TE</td>\n",
       "      <td>56.75</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>anmol</td>\n",
       "      <td>BE</td>\n",
       "      <td>78.66</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  roll     name class  marks age\n",
       "0    1     anil    TE  56.77  22\n",
       "1    2     amit    TE  59.77  21\n",
       "2    3   aniket    BE  76.88  19\n",
       "3    4  ajinkya    TE  69.66  20\n",
       "4    5     asha    TE  63.28  20\n",
       "5    6   ayesha    BE  49.55  20\n",
       "6    7     amar    BE  65.34  19\n",
       "7    8    amita    BE  68.33  23\n",
       "8    9     amol    TE  56.75  20\n",
       "9   10    anmol    BE  78.66  21"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(arr[1:], columns=arr[0])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
