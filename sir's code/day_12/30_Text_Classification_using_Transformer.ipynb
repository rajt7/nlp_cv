{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ky84E7MWGL05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-02 23:52:48.386706: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-01-02 23:52:48.435381: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-02 23:52:48.435417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-02 23:52:48.436526: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-02 23:52:48.443847: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-02 23:52:49.414128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fcKd72L_HACt"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(Layer):\n",
        "  def __init__(self, embed_dim, num_head, ff_dim, rate  = 0.1):\n",
        "\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(num_heads = num_head , key_dim = embed_dim)\n",
        "\n",
        "    self.ffn = Sequential(\n",
        "        [Dense(ff_dim, activation = 'relu'), Dense(embed_dim)],\n",
        "    )\n",
        "\n",
        "    self.layernorm1 = LayerNormalization(epsilon = 1e-6)\n",
        "    self.layernorm2 = LayerNormalization(epsilon = 1e-6)\n",
        "\n",
        "    self.dropout1 = Dropout(rate)\n",
        "    self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    attn_output = self.att(inputs, inputs)\n",
        "\n",
        "    attn_output = self.dropout1(attn_output, training = training)\n",
        "\n",
        "    out1 = self.layernorm1(inputs + attn_output)\n",
        "\n",
        "    ffn_output = self.ffn(out1)\n",
        "\n",
        "    ffn_output = self.dropout2(ffn_output, training = training)\n",
        "\n",
        "    return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTCaUL45MEEY"
      },
      "source": [
        "# Implementing Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RRjAmmASMZwc"
      },
      "outputs": [],
      "source": [
        "class TokenAndPositionEmbedding(Layer):\n",
        "\n",
        "  def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "    super().__init__()\n",
        "    self.token_emb = Embedding(input_dim= vocab_size, output_dim=embed_dim)\n",
        "    self.pos_emb = Embedding(input_dim= maxlen, output_dim=embed_dim)\n",
        "\n",
        "\n",
        "  def call(self, x):\n",
        "    maxlen = tf.shape(x)[-1]\n",
        "    positions = tf.range(start = 0, limit = maxlen, delta = 1)\n",
        "    postions = self.pos_emb(positions)\n",
        "    x = self.token_emb(x)\n",
        "    return x + postions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MDU7xouPHFx",
        "outputId": "63eaa4fb-273f-4253-af82-04a611f6d854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 3s 0us/step\n",
            "25000 Training sequences\n",
            "25000 Validation sequences\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 20000 # Only consider the top 20k words\n",
        "maxlen = 200\n",
        "(x_train, y_train), (x_val, y_val) = imdb.load_data(num_words = vocab_size)\n",
        "print(len(x_train), \"Training sequences\")\n",
        "print(len(x_val), \"Validation sequences\")\n",
        "x_train = pad_sequences(x_train, maxlen = maxlen)\n",
        "x_val = pad_sequences(x_val, maxlen = maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpXRL5UYnBnQ",
        "outputId": "a8755307-42dc-488d-a045-824d0f6283ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([    5,    25,   100,    43,   838,   112,    50,   670,     2,\n",
              "           9,    35,   480,   284,     5,   150,     4,   172,   112,\n",
              "         167,     2,   336,   385,    39,     4,   172,  4536,  1111,\n",
              "          17,   546,    38,    13,   447,     4,   192,    50,    16,\n",
              "           6,   147,  2025,    19,    14,    22,     4,  1920,  4613,\n",
              "         469,     4,    22,    71,    87,    12,    16,    43,   530,\n",
              "          38,    76,    15,    13,  1247,     4,    22,    17,   515,\n",
              "          17,    12,    16,   626,    18, 19193,     5,    62,   386,\n",
              "          12,     8,   316,     8,   106,     5,     4,  2223,  5244,\n",
              "          16,   480,    66,  3785,    33,     4,   130,    12,    16,\n",
              "          38,   619,     5,    25,   124,    51,    36,   135,    48,\n",
              "          25,  1415,    33,     6,    22,    12,   215,    28,    77,\n",
              "          52,     5,    14,   407,    16,    82, 10311,     8,     4,\n",
              "         107,   117,  5952,    15,   256,     4,     2,     7,  3766,\n",
              "           5,   723,    36,    71,    43,   530,   476,    26,   400,\n",
              "         317,    46,     7,     4, 12118,  1029,    13,   104,    88,\n",
              "           4,   381,    15,   297,    98,    32,  2071,    56,    26,\n",
              "         141,     6,   194,  7486,    18,     4,   226,    22,    21,\n",
              "         134,   476,    26,   480,     5,   144,    30,  5535,    18,\n",
              "          51,    36,    28,   224,    92,    25,   104,     4,   226,\n",
              "          65,    16,    38,  1334,    88,    12,    16,   283,     5,\n",
              "          16,  4472,   113,   103,    32,    15,    16,  5345,    19,\n",
              "         178,    32], dtype=int32)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsH1ly4WPG36",
        "outputId": "8645d904-10ce-4cc8-86ad-db2d413d95ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nBJDAafRRByR"
      },
      "outputs": [],
      "source": [
        "embed_dim = 32\n",
        "num_heads = 2\n",
        "ff_dim = 32\n",
        "\n",
        "inputs = Input(shape = (maxlen,))\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(20, activation = 'relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "outputs = Dense(2, activation = 'softmax')(x)\n",
        "\n",
        "model = Model(inputs = inputs, outputs = outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k5Sh_JSepcz",
        "outputId": "4d1f4e15-7d00-47fa-f7f8-3e791e70e4e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 37s 44ms/step - loss: 0.3798 - accuracy: 0.8209 - val_loss: 0.2878 - val_accuracy: 0.8784\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.1930 - accuracy: 0.9256 - val_loss: 0.3040 - val_accuracy: 0.8754\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 0.1319 - accuracy: 0.9530 - val_loss: 0.4069 - val_accuracy: 0.8598\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 0.0813 - accuracy: 0.9726 - val_loss: 0.5010 - val_accuracy: 0.8519\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 34s 44ms/step - loss: 0.0526 - accuracy: 0.9825 - val_loss: 0.5380 - val_accuracy: 0.8407\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 34s 43ms/step - loss: 0.0408 - accuracy: 0.9864 - val_loss: 0.7301 - val_accuracy: 0.8442\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 34s 44ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 0.8390 - val_accuracy: 0.8369\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 34s 43ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.8326 - val_accuracy: 0.8362\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 34s 43ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.8715 - val_accuracy: 0.8340\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 34s 44ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.8571 - val_accuracy: 0.8323\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size = 32, epochs = 10, validation_data = (x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "och_aMeHkB9W",
        "outputId": "54bf1ef9-e47a-4e73-c890-7432d920a2ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 12s 16ms/step - loss: 0.8571 - accuracy: 0.8323\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.8571203947067261, 0.8322799801826477]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oyE8E4YWlx80"
      },
      "outputs": [],
      "source": [
        "def predict_text(text):\n",
        "  text = pad_sequences(text, maxlen = maxlen)\n",
        "  prediction = model.predict(text)\n",
        "  return prediction.argmax(axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Zs6mmIBlmxQe"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"It is no wonder that the film has such a high rating, it is quite literally breathtaking. What can I say that hasn't said before? Not much, it's the story, the acting, the premise, but most of all, this movie is about how it makes you feel. Sometimes you watch a film, and can't remember it days later, this film loves with you, once you've seen it, you don't forget. The ultimate story of friendship, of hope, and of life, and overcoming adversity. I understand why so many class this as the best film of all time, it isn't mine, but I get it. If you haven't seen it, or haven't seen it for some time, you need to watch it, it's amazing.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "XLKcryUwmu-_",
        "outputId": "3f52dac2-bcd4-4375-b1e3-03ce5a52f2ab"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: 'I'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/dai/Desktop/AI/nlp_cv/day_12/30_Text_Classification_using_Transformer.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dai/Desktop/AI/nlp_cv/day_12/30_Text_Classification_using_Transformer.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predict_text(text)\n",
            "\u001b[1;32m/home/dai/Desktop/AI/nlp_cv/day_12/30_Text_Classification_using_Transformer.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Desktop/AI/nlp_cv/day_12/30_Text_Classification_using_Transformer.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_text\u001b[39m(text):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dai/Desktop/AI/nlp_cv/day_12/30_Text_Classification_using_Transformer.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   text \u001b[39m=\u001b[39m pad_sequences(text, maxlen \u001b[39m=\u001b[39m maxlen)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Desktop/AI/nlp_cv/day_12/30_Text_Classification_using_Transformer.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(text)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Desktop/AI/nlp_cv/day_12/30_Text_Classification_using_Transformer.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m prediction\u001b[39m.\u001b[39margmax(axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/dnn/lib/python3.11/site-packages/keras/src/utils/data_utils.py:1132\u001b[0m, in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTruncating type \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtruncating\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m not understood\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# check `trunc` has expected shape\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m trunc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(trunc, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m   1133\u001b[0m \u001b[39mif\u001b[39;00m trunc\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:] \u001b[39m!=\u001b[39m sample_shape:\n\u001b[1;32m   1134\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1135\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of sample \u001b[39m\u001b[39m{\u001b[39;00mtrunc\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:]\u001b[39m}\u001b[39;00m\u001b[39m of sequence at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1136\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mposition \u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m is different from expected shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1137\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msample_shape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1138\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'I'"
          ]
        }
      ],
      "source": [
        "predict_text(text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
